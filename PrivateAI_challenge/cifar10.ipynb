{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook = sy.TorchHook(torch)  \n",
    "# bob = sy.VirtualWorker(hook, id=\"bob\") \n",
    "# alice = sy.VirtualWorker(hook, id=\"alice\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self):\n",
    "        self.batch_size = 256\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 10\n",
    "        self.lr = 0.01\n",
    "        self.momentum = 0.5\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.save_model = False\n",
    "\n",
    "args = Arguments()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "# federated_train_loader = sy.FederatedDataLoader(\n",
    "federated_train_loader = DataLoader(\n",
    "        datasets.CIFAR10(root='./dataset', \n",
    "                     train=True,\n",
    "                     download=True, \n",
    "                     transform=transform), \n",
    "    batch_size=args.batch_size, \n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.CIFAR10(root='./dataset', \n",
    "                     train=False,\n",
    "                     download=True, \n",
    "                     transform=transform), \n",
    "    batch_size=args.test_batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogLeNet(\n",
      "  (conv1): BasicConv2d(\n",
      "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (conv2): BasicConv2d(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv3): BasicConv2d(\n",
      "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception3a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception3b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception4a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4c): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4d): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception4e): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (inception5a): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (inception5b): Inception(\n",
      "    (branch1): BasicConv2d(\n",
      "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (branch2): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch3): Sequential(\n",
      "      (0): BasicConv2d(\n",
      "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (branch4): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
      "      (1): BasicConv2d(\n",
      "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (dropout): Dropout(p=0.2)\n",
      "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "# if use_cuda:\n",
    "#     googlenet.cuda()\n",
    "    \n",
    "print(googlenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(googlenet.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(model, device, federated_train_loader, optimizer, epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(federated_train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "#             loss = loss.get() # <-- NEW: get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx / len(federated_train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "Train Epoch: 1 [0/50176 (0%)]\tLoss: 8.928292\n",
      "Train Epoch: 1 [7680/50176 (15%)]\tLoss: 3.703995\n",
      "Train Epoch: 1 [15360/50176 (31%)]\tLoss: 2.397283\n",
      "Train Epoch: 1 [23040/50176 (46%)]\tLoss: 2.022807\n",
      "Train Epoch: 1 [30720/50176 (61%)]\tLoss: 1.713052\n",
      "Train Epoch: 1 [38400/50176 (77%)]\tLoss: 1.682305\n",
      "Train Epoch: 1 [46080/50176 (92%)]\tLoss: 1.458177\n",
      "Test set: Average loss: 1.3669, Accuracy: 534/10000 (5%)\n",
      "Test set: Average loss: 2.8142, Accuracy: 1060/10000 (11%)\n",
      "Test set: Average loss: 4.1787, Accuracy: 1586/10000 (16%)\n",
      "Test set: Average loss: 5.5149, Accuracy: 2137/10000 (21%)\n",
      "Test set: Average loss: 6.8553, Accuracy: 2695/10000 (27%)\n",
      "Test set: Average loss: 8.2457, Accuracy: 3219/10000 (32%)\n",
      "Test set: Average loss: 9.6673, Accuracy: 3743/10000 (37%)\n",
      "Test set: Average loss: 11.0824, Accuracy: 4273/10000 (43%)\n",
      "Test set: Average loss: 12.4203, Accuracy: 4829/10000 (48%)\n",
      "Test set: Average loss: 13.7572, Accuracy: 5363/10000 (54%)\n",
      "\n",
      "Epoch: 2\n",
      "Train Epoch: 2 [0/50176 (0%)]\tLoss: 1.390227\n",
      "Train Epoch: 2 [7680/50176 (15%)]\tLoss: 1.412032\n",
      "Train Epoch: 2 [15360/50176 (31%)]\tLoss: 1.152208\n",
      "Train Epoch: 2 [23040/50176 (46%)]\tLoss: 1.161556\n",
      "Train Epoch: 2 [30720/50176 (61%)]\tLoss: 1.300525\n",
      "Train Epoch: 2 [38400/50176 (77%)]\tLoss: 1.052341\n",
      "Train Epoch: 2 [46080/50176 (92%)]\tLoss: 1.033923\n",
      "Test set: Average loss: 1.1929, Accuracy: 603/10000 (6%)\n",
      "Test set: Average loss: 2.4900, Accuracy: 1210/10000 (12%)\n",
      "Test set: Average loss: 3.7119, Accuracy: 1801/10000 (18%)\n",
      "Test set: Average loss: 4.8601, Accuracy: 2427/10000 (24%)\n",
      "Test set: Average loss: 6.0280, Accuracy: 3045/10000 (30%)\n",
      "Test set: Average loss: 7.2496, Accuracy: 3644/10000 (36%)\n",
      "Test set: Average loss: 8.5321, Accuracy: 4243/10000 (42%)\n",
      "Test set: Average loss: 9.7471, Accuracy: 4851/10000 (49%)\n",
      "Test set: Average loss: 10.9468, Accuracy: 5459/10000 (55%)\n",
      "Test set: Average loss: 12.1866, Accuracy: 6055/10000 (61%)\n",
      "\n",
      "Epoch: 3\n",
      "Train Epoch: 3 [0/50176 (0%)]\tLoss: 1.146045\n",
      "Train Epoch: 3 [7680/50176 (15%)]\tLoss: 0.966585\n",
      "Train Epoch: 3 [15360/50176 (31%)]\tLoss: 1.014492\n",
      "Train Epoch: 3 [23040/50176 (46%)]\tLoss: 1.034117\n",
      "Train Epoch: 3 [30720/50176 (61%)]\tLoss: 0.904222\n",
      "Train Epoch: 3 [38400/50176 (77%)]\tLoss: 1.069890\n",
      "Train Epoch: 3 [46080/50176 (92%)]\tLoss: 0.950329\n",
      "Test set: Average loss: 0.9981, Accuracy: 657/10000 (7%)\n",
      "Test set: Average loss: 2.0775, Accuracy: 1290/10000 (13%)\n",
      "Test set: Average loss: 3.1111, Accuracy: 1938/10000 (19%)\n",
      "Test set: Average loss: 4.0770, Accuracy: 2615/10000 (26%)\n",
      "Test set: Average loss: 5.0805, Accuracy: 3284/10000 (33%)\n",
      "Test set: Average loss: 6.0858, Accuracy: 3955/10000 (40%)\n",
      "Test set: Average loss: 7.1273, Accuracy: 4598/10000 (46%)\n",
      "Test set: Average loss: 8.1437, Accuracy: 5240/10000 (52%)\n",
      "Test set: Average loss: 9.1648, Accuracy: 5885/10000 (59%)\n",
      "Test set: Average loss: 10.1789, Accuracy: 6536/10000 (65%)\n",
      "\n",
      "Epoch: 4\n",
      "Train Epoch: 4 [0/50176 (0%)]\tLoss: 0.943853\n",
      "Train Epoch: 4 [7680/50176 (15%)]\tLoss: 0.891331\n",
      "Train Epoch: 4 [15360/50176 (31%)]\tLoss: 0.821389\n",
      "Train Epoch: 4 [23040/50176 (46%)]\tLoss: 0.848399\n",
      "Train Epoch: 4 [30720/50176 (61%)]\tLoss: 0.825444\n",
      "Train Epoch: 4 [38400/50176 (77%)]\tLoss: 0.887010\n",
      "Train Epoch: 4 [46080/50176 (92%)]\tLoss: 0.919935\n",
      "Test set: Average loss: 0.9633, Accuracy: 678/10000 (7%)\n",
      "Test set: Average loss: 1.9800, Accuracy: 1353/10000 (14%)\n",
      "Test set: Average loss: 2.9591, Accuracy: 2018/10000 (20%)\n",
      "Test set: Average loss: 3.8732, Accuracy: 2717/10000 (27%)\n",
      "Test set: Average loss: 4.8392, Accuracy: 3410/10000 (34%)\n",
      "Test set: Average loss: 5.7804, Accuracy: 4095/10000 (41%)\n",
      "Test set: Average loss: 6.7765, Accuracy: 4755/10000 (48%)\n",
      "Test set: Average loss: 7.7587, Accuracy: 5414/10000 (54%)\n",
      "Test set: Average loss: 8.7296, Accuracy: 6095/10000 (61%)\n",
      "Test set: Average loss: 9.7296, Accuracy: 6754/10000 (68%)\n",
      "\n",
      "Epoch: 5\n",
      "Train Epoch: 5 [0/50176 (0%)]\tLoss: 0.767320\n",
      "Train Epoch: 5 [7680/50176 (15%)]\tLoss: 0.680792\n",
      "Train Epoch: 5 [15360/50176 (31%)]\tLoss: 0.704081\n",
      "Train Epoch: 5 [23040/50176 (46%)]\tLoss: 0.643022\n",
      "Train Epoch: 5 [30720/50176 (61%)]\tLoss: 0.806425\n",
      "Train Epoch: 5 [38400/50176 (77%)]\tLoss: 0.783407\n",
      "Train Epoch: 5 [46080/50176 (92%)]\tLoss: 0.716446\n",
      "Test set: Average loss: 0.9475, Accuracy: 686/10000 (7%)\n",
      "Test set: Average loss: 1.9351, Accuracy: 1353/10000 (14%)\n",
      "Test set: Average loss: 2.8880, Accuracy: 2034/10000 (20%)\n",
      "Test set: Average loss: 3.7846, Accuracy: 2733/10000 (27%)\n",
      "Test set: Average loss: 4.7062, Accuracy: 3436/10000 (34%)\n",
      "Test set: Average loss: 5.6122, Accuracy: 4128/10000 (41%)\n",
      "Test set: Average loss: 6.5673, Accuracy: 4805/10000 (48%)\n",
      "Test set: Average loss: 7.5200, Accuracy: 5479/10000 (55%)\n",
      "Test set: Average loss: 8.4664, Accuracy: 6165/10000 (62%)\n",
      "Test set: Average loss: 9.4229, Accuracy: 6842/10000 (68%)\n",
      "\n",
      "Epoch: 6\n",
      "Train Epoch: 6 [0/50176 (0%)]\tLoss: 0.739013\n",
      "Train Epoch: 6 [7680/50176 (15%)]\tLoss: 0.658523\n",
      "Train Epoch: 6 [15360/50176 (31%)]\tLoss: 0.692084\n",
      "Train Epoch: 6 [23040/50176 (46%)]\tLoss: 0.691234\n",
      "Train Epoch: 6 [30720/50176 (61%)]\tLoss: 0.632673\n",
      "Train Epoch: 6 [38400/50176 (77%)]\tLoss: 0.722640\n",
      "Train Epoch: 6 [46080/50176 (92%)]\tLoss: 0.611461\n",
      "Test set: Average loss: 0.9271, Accuracy: 695/10000 (7%)\n",
      "Test set: Average loss: 1.9085, Accuracy: 1382/10000 (14%)\n",
      "Test set: Average loss: 2.8520, Accuracy: 2072/10000 (21%)\n",
      "Test set: Average loss: 3.7565, Accuracy: 2775/10000 (28%)\n",
      "Test set: Average loss: 4.6818, Accuracy: 3482/10000 (35%)\n",
      "Test set: Average loss: 5.5650, Accuracy: 4184/10000 (42%)\n",
      "Test set: Average loss: 6.5014, Accuracy: 4877/10000 (49%)\n",
      "Test set: Average loss: 7.4496, Accuracy: 5555/10000 (56%)\n",
      "Test set: Average loss: 8.3795, Accuracy: 6263/10000 (63%)\n",
      "Test set: Average loss: 9.3295, Accuracy: 6949/10000 (69%)\n",
      "\n",
      "Epoch: 7\n",
      "Train Epoch: 7 [0/50176 (0%)]\tLoss: 0.611610\n",
      "Train Epoch: 7 [7680/50176 (15%)]\tLoss: 0.633058\n",
      "Train Epoch: 7 [15360/50176 (31%)]\tLoss: 0.513801\n",
      "Train Epoch: 7 [23040/50176 (46%)]\tLoss: 0.614852\n",
      "Train Epoch: 7 [30720/50176 (61%)]\tLoss: 0.634116\n",
      "Train Epoch: 7 [38400/50176 (77%)]\tLoss: 0.650498\n",
      "Train Epoch: 7 [46080/50176 (92%)]\tLoss: 0.540311\n",
      "Test set: Average loss: 0.9419, Accuracy: 705/10000 (7%)\n",
      "Test set: Average loss: 1.9055, Accuracy: 1403/10000 (14%)\n",
      "Test set: Average loss: 2.8680, Accuracy: 2098/10000 (21%)\n",
      "Test set: Average loss: 3.7681, Accuracy: 2812/10000 (28%)\n",
      "Test set: Average loss: 4.7090, Accuracy: 3518/10000 (35%)\n",
      "Test set: Average loss: 5.6007, Accuracy: 4223/10000 (42%)\n",
      "Test set: Average loss: 6.5423, Accuracy: 4912/10000 (49%)\n",
      "Test set: Average loss: 7.5073, Accuracy: 5593/10000 (56%)\n",
      "Test set: Average loss: 8.4501, Accuracy: 6296/10000 (63%)\n",
      "Test set: Average loss: 9.4307, Accuracy: 6978/10000 (70%)\n",
      "\n",
      "Epoch: 8\n",
      "Train Epoch: 8 [0/50176 (0%)]\tLoss: 0.471047\n",
      "Train Epoch: 8 [7680/50176 (15%)]\tLoss: 0.537465\n",
      "Train Epoch: 8 [15360/50176 (31%)]\tLoss: 0.438154\n",
      "Train Epoch: 8 [23040/50176 (46%)]\tLoss: 0.512601\n",
      "Train Epoch: 8 [30720/50176 (61%)]\tLoss: 0.491741\n",
      "Train Epoch: 8 [38400/50176 (77%)]\tLoss: 0.474910\n",
      "Train Epoch: 8 [46080/50176 (92%)]\tLoss: 0.453018\n",
      "Test set: Average loss: 0.9652, Accuracy: 690/10000 (7%)\n",
      "Test set: Average loss: 1.9610, Accuracy: 1383/10000 (14%)\n",
      "Test set: Average loss: 2.9522, Accuracy: 2075/10000 (21%)\n",
      "Test set: Average loss: 3.8727, Accuracy: 2791/10000 (28%)\n",
      "Test set: Average loss: 4.8262, Accuracy: 3507/10000 (35%)\n",
      "Test set: Average loss: 5.7186, Accuracy: 4223/10000 (42%)\n",
      "Test set: Average loss: 6.6876, Accuracy: 4921/10000 (49%)\n",
      "Test set: Average loss: 7.6633, Accuracy: 5617/10000 (56%)\n",
      "Test set: Average loss: 8.6265, Accuracy: 6312/10000 (63%)\n",
      "Test set: Average loss: 9.6284, Accuracy: 6997/10000 (70%)\n",
      "\n",
      "Epoch: 9\n",
      "Train Epoch: 9 [0/50176 (0%)]\tLoss: 0.410965\n",
      "Train Epoch: 9 [7680/50176 (15%)]\tLoss: 0.524307\n",
      "Train Epoch: 9 [15360/50176 (31%)]\tLoss: 0.413186\n",
      "Train Epoch: 9 [23040/50176 (46%)]\tLoss: 0.399900\n",
      "Train Epoch: 9 [30720/50176 (61%)]\tLoss: 0.361203\n",
      "Train Epoch: 9 [38400/50176 (77%)]\tLoss: 0.496954\n",
      "Train Epoch: 9 [46080/50176 (92%)]\tLoss: 0.352974\n",
      "Test set: Average loss: 0.9990, Accuracy: 703/10000 (7%)\n",
      "Test set: Average loss: 2.0532, Accuracy: 1411/10000 (14%)\n",
      "Test set: Average loss: 3.1270, Accuracy: 2095/10000 (21%)\n",
      "Test set: Average loss: 4.1204, Accuracy: 2806/10000 (28%)\n",
      "Test set: Average loss: 5.1512, Accuracy: 3522/10000 (35%)\n",
      "Test set: Average loss: 6.0760, Accuracy: 4233/10000 (42%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 7.0975, Accuracy: 4922/10000 (49%)\n",
      "Test set: Average loss: 8.1298, Accuracy: 5596/10000 (56%)\n",
      "Test set: Average loss: 9.1301, Accuracy: 6289/10000 (63%)\n",
      "Test set: Average loss: 10.1788, Accuracy: 6982/10000 (70%)\n",
      "\n",
      "Epoch: 10\n",
      "Train Epoch: 10 [0/50176 (0%)]\tLoss: 0.314349\n",
      "Train Epoch: 10 [7680/50176 (15%)]\tLoss: 0.341194\n",
      "Train Epoch: 10 [15360/50176 (31%)]\tLoss: 0.322162\n",
      "Train Epoch: 10 [23040/50176 (46%)]\tLoss: 0.377497\n",
      "Train Epoch: 10 [30720/50176 (61%)]\tLoss: 0.266319\n",
      "Train Epoch: 10 [38400/50176 (77%)]\tLoss: 0.448918\n",
      "Train Epoch: 10 [46080/50176 (92%)]\tLoss: 0.309196\n",
      "Test set: Average loss: 1.0289, Accuracy: 706/10000 (7%)\n",
      "Test set: Average loss: 2.0888, Accuracy: 1401/10000 (14%)\n",
      "Test set: Average loss: 3.1669, Accuracy: 2095/10000 (21%)\n",
      "Test set: Average loss: 4.1480, Accuracy: 2814/10000 (28%)\n",
      "Test set: Average loss: 5.1715, Accuracy: 3539/10000 (35%)\n",
      "Test set: Average loss: 6.0992, Accuracy: 4257/10000 (43%)\n",
      "Test set: Average loss: 7.1038, Accuracy: 4954/10000 (50%)\n",
      "Test set: Average loss: 8.1454, Accuracy: 5648/10000 (56%)\n",
      "Test set: Average loss: 9.1564, Accuracy: 6348/10000 (63%)\n",
      "Test set: Average loss: 10.2269, Accuracy: 7043/10000 (70%)\n",
      "Wall time: 5min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = googlenet.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr) \n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(model, device, federated_train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "if (args.save_model):\n",
    "    torch.save(model.state_dict(), \"./models/CIFAR10_cnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
