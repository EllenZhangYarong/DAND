{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_data'\n",
    "test_dir = data_dir + '/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                    transforms.CenterCrop(224),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                    ])\n",
    "\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "test_image_datasets = datasets.ImageFolder(test_dir, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data loaders (combine dataset and sampler)\n",
    "test_loader = torch.utils.data.DataLoader(test_image_datasets, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 102)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout(x)        \n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv4(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv5(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool(F.relu(self.conv6(x)))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.view(-1, 128 * 7 * 7)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_checkpoint(model,filename):\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading model '{}'\".format(filename))\n",
    "        model.load_state_dict(torch.load(filename))\n",
    "        print(\"=> loaded model from '{}'\".format(filename))\n",
    "    else:\n",
    "        print(\"=> no model found at '{}'\".format(filename))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6272, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=102, bias=True)\n",
      "  (dropout): Dropout(p=0.25)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create a complete CNN\n",
    "model = Net()\n",
    "print(model)\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if train_on_gpu:\n",
    "    torch.cuda.empty_cache()\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, amsgrad=True, eps=1e-8, weight_decay=1e-5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading model 'model_flower_v9.pt'\n",
      "=> loaded model from 'model_flower_v9.pt'\n"
     ]
    }
   ],
   "source": [
    "model = load_checkpoint(model, '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Test result----------------------\n",
      "0 -->  [1 0 0 0 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "1 -->  [1 1 1 1 1 1 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "2 -->  [0 0 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "3 -->  [0 0 0 1 0 1 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "4 -->  [0 1 1 1 1 0 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "5 -->  [1 1 1 1 0 0 0 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "6 -->  [1 1 0 1 0 0 1 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "7 -->  [0 1 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "8 -->  [1 0 1 1 0 1 1 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "9 -->  [1 0 1 0 0 0 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "10 -->  [0 0 1 1 0 0 0 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "11 -->  [0 0 1 0 1 0 1 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "12 -->  [0 0 0 1 1 1 1 1 0 1]\n",
      "-------------------Test result----------------------\n",
      "13 -->  [1 0 0 0 0 0 0 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "14 -->  [0 0 0 1 1 1 0 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "15 -->  [0 0 0 0 0 0 0 1 0 1]\n",
      "-------------------Test result----------------------\n",
      "16 -->  [0 0 1 0 1 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "17 -->  [1 1 1 0 1 0 1 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "18 -->  [1 1 0 1 0 1 1 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "19 -->  [1 1 0 1 0 0 0 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "20 -->  [1 0 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "21 -->  [0 0 0 0 0 0 0 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "22 -->  [0 0 1 0 1 0 0 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "23 -->  [0 0 0 1 0 0 0 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "24 -->  [0 0 0 1 0 1 1 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "25 -->  [1 0 1 0 1 1 0 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "26 -->  [0 1 0 1 0 1 1 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "27 -->  [0 1 1 0 1 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "28 -->  [1 0 0 1 1 0 1 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "29 -->  [0 0 0 0 0 0 1 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "30 -->  [0 1 0 1 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "31 -->  [0 0 1 1 1 0 0 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "32 -->  [1 1 1 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "33 -->  [0 0 0 1 0 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "34 -->  [0 0 0 0 1 1 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "35 -->  [0 1 0 0 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "36 -->  [1 0 1 1 1 1 1 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "37 -->  [1 1 1 1 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "38 -->  [0 1 1 0 1 0 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "39 -->  [1 1 1 1 0 1 0 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "40 -->  [1 1 1 1 1 1 1 1 0 0]\n",
      "-------------------Test result----------------------\n",
      "41 -->  [0 0 1 0 1 0 1 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "42 -->  [1 1 1 1 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "43 -->  [1 1 1 1 0 0 0 1 0 0]\n",
      "-------------------Test result----------------------\n",
      "44 -->  [0 1 1 0 0 1 0 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "45 -->  [1 0 1 1 1 0 1 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "46 -->  [0 0 0 1 0 1 1 1 0 1]\n",
      "-------------------Test result----------------------\n",
      "47 -->  [0 0 1 0 1 1 1 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "48 -->  [0 0 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "49 -->  [0 0 0 1 0 0 0 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "50 -->  [0 0 1 1 1 1 1 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "51 -->  [0 1 1 1 1 1 1 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "52 -->  [1 1 1 0 1 1 1 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "53 -->  [1 0 0 0 0 0 0 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "54 -->  [1 1 1 1 1 1 1 1 0 1]\n",
      "-------------------Test result----------------------\n",
      "55 -->  [1 0 1 0 0 0 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "56 -->  [1 1 1 1 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "57 -->  [1 1 0 1 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "58 -->  [0 1 0 1 1 1 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "59 -->  [1 0 1 0 1 1 0 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "60 -->  [1 1 0 1 0 1 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "61 -->  [0 0 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "62 -->  [1 0 0 1 0 1 1 1 0 1]\n",
      "-------------------Test result----------------------\n",
      "63 -->  [0 1 1 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "64 -->  [0 0 0 0 0 0 0 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "65 -->  [0 1 1 0 1 0 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "66 -->  [0 0 0 1 0 0 0 1 0 0]\n",
      "-------------------Test result----------------------\n",
      "67 -->  [1 0 0 0 1 1 0 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "68 -->  [0 0 1 1 0 0 1 1 1 1]\n",
      "-------------------Test result----------------------\n",
      "69 -->  [0 0 0 0 1 0 0 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "70 -->  [1 0 1 0 0 0 0 1 0 1]\n",
      "-------------------Test result----------------------\n",
      "71 -->  [0 1 1 1 1 1 1 0 0 1]\n",
      "-------------------Test result----------------------\n",
      "72 -->  [0 1 0 0 0 0 0 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "73 -->  [0 0 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "74 -->  [1 0 1 0 1 1 0 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "75 -->  [1 0 0 1 1 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "76 -->  [0 0 0 1 0 0 0 1 1 0]\n",
      "-------------------Test result----------------------\n",
      "77 -->  [0 0 1 1 1 1 1 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "78 -->  [0 0 0 0 0 0 0 0 0 0]\n",
      "-------------------Test result----------------------\n",
      "79 -->  [0 0 0 0 0 0 0 0 1 1]\n",
      "-------------------Test result----------------------\n",
      "80 -->  [0 0 0 0 0 0 1 0 1 0]\n",
      "-------------------Test result----------------------\n",
      "81 -->  [1 0 0 0 0 0 0 0 0]\n",
      "Test Loss: 2.045819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# track test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(102))\n",
    "class_total = list(0. for i in range(102))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# iterate over test data\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    if train_on_gpu:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    \n",
    "    print(\"-------------------Test result----------------------\")\n",
    "    print(batch_idx,\"--> \", correct)\n",
    "        \n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target.data)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "        \n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)\n",
    "    \n",
    "cat_to_name['105'] = \"Noise\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of  1 -> pink primrose: 40.00% ( 2/ 5)\n",
      "Test Accuracy of  2 -> hard-leaved pocket orchid: 100.00% ( 3/ 3)\n",
      "Test Accuracy of  3 -> canterbury bells: 100.00% ( 8/ 8)\n",
      "Test Accuracy of  4 -> sweet pea: 50.00% ( 2/ 4)\n",
      "Test Accuracy of  5 -> english marigold: 0.00% ( 0/ 6)\n",
      "Test Accuracy of  6 -> tiger lily: 11.11% ( 1/ 9)\n",
      "Test Accuracy of  7 -> moon orchid: 66.67% ( 6/ 9)\n",
      "Test Accuracy of  8 -> bird of paradise: 50.00% ( 3/ 6)\n",
      "Test Accuracy of  9 -> monkshood: 100.00% ( 3/ 3)\n",
      "Test Accuracy of 10 -> globe thistle: 25.00% ( 1/ 4)\n",
      "Test Accuracy of 11 -> snapdragon: 33.33% ( 1/ 3)\n",
      "Test Accuracy of 12 -> colt's foot: 66.67% ( 6/ 9)\n",
      "Test Accuracy of 13 -> king protea: 16.67% ( 1/ 6)\n",
      "Test Accuracy of 14 -> spear thistle: 14.29% ( 1/ 7)\n",
      "Test Accuracy of 15 -> yellow iris: 80.00% ( 4/ 5)\n",
      "Test Accuracy of 16 -> globe-flower: 66.67% ( 2/ 3)\n",
      "Test Accuracy of 17 -> purple coneflower: 50.00% ( 1/ 2)\n",
      "Test Accuracy of 18 -> peruvian lily: 25.00% ( 1/ 4)\n",
      "Test Accuracy of 19 -> balloon flower: 42.86% ( 3/ 7)\n",
      "Test Accuracy of 20 -> giant white arum lily: 50.00% ( 1/ 2)\n",
      "Test Accuracy of 21 -> fire lily: 40.00% ( 2/ 5)\n",
      "Test Accuracy of 22 -> pincushion flower: 40.00% ( 2/ 5)\n",
      "Test Accuracy of 23 -> fritillary: 33.33% ( 1/ 3)\n",
      "Test Accuracy of 24 -> red ginger: 50.00% ( 3/ 6)\n",
      "Test Accuracy of 25 -> grape hyacinth: 66.67% ( 6/ 9)\n",
      "Test Accuracy of 26 -> corn poppy: 0.00% ( 0/ 2)\n",
      "Test Accuracy of 27 -> prince of wales feathers: 28.57% ( 4/14)\n",
      "Test Accuracy of 28 -> stemless gentian: 50.00% ( 1/ 2)\n",
      "Test Accuracy of 29 -> artichoke: 0.00% ( 0/ 6)\n",
      "Test Accuracy of 30 -> sweet william: 50.00% ( 4/ 8)\n",
      "Test Accuracy of 31 -> carnation: 0.00% ( 0/ 5)\n",
      "Test Accuracy of 32 -> garden phlox: 66.67% ( 4/ 6)\n",
      "Test Accuracy of 33 -> love in the mist: 71.43% ( 5/ 7)\n",
      "Test Accuracy of 34 -> mexican aster: 75.00% ( 6/ 8)\n",
      "Test Accuracy of 35 -> alpine sea holly: 37.50% ( 3/ 8)\n",
      "Test Accuracy of 36 -> ruby-lipped cattleya: 20.00% ( 1/ 5)\n",
      "Test Accuracy of 37 -> cape flower: 0.00% ( 0/ 6)\n",
      "Test Accuracy of 38 -> great masterwort: 0.00% ( 0/ 8)\n",
      "Test Accuracy of 39 -> siam tulip: 35.71% ( 5/14)\n",
      "Test Accuracy of 40 -> lenten rose: 25.00% ( 1/ 4)\n",
      "Test Accuracy of 41 -> barbeton daisy: 37.50% ( 6/16)\n",
      "Test Accuracy of 42 -> daffodil: 63.64% ( 7/11)\n",
      "Test Accuracy of 43 -> sword lily: 66.67% ( 2/ 3)\n",
      "Test Accuracy of 44 -> poinsettia: 38.10% ( 8/21)\n",
      "Test Accuracy of 45 -> bolero deep blue: 33.33% ( 1/ 3)\n",
      "Test Accuracy of 46 -> wallflower: 0.00% ( 0/ 5)\n",
      "Test Accuracy of 47 -> marigold: 66.67% ( 2/ 3)\n",
      "Test Accuracy of 48 -> buttercup: 50.00% ( 2/ 4)\n",
      "Test Accuracy of 49 -> oxeye daisy: 87.50% ( 7/ 8)\n",
      "Test Accuracy of 50 -> common dandelion: 41.67% (10/24)\n",
      "Test Accuracy of 51 -> petunia: 62.50% ( 5/ 8)\n",
      "Test Accuracy of 52 -> wild pansy: 35.71% ( 5/14)\n",
      "Test Accuracy of 53 -> primula: 100.00% ( 4/ 4)\n",
      "Test Accuracy of 54 -> sunflower: 85.71% ( 6/ 7)\n",
      "Test Accuracy of 55 -> pelargonium: 75.00% ( 6/ 8)\n",
      "Test Accuracy of 56 -> bishop of llandaff: 72.73% ( 8/11)\n",
      "Test Accuracy of 57 -> gaura: 71.43% (10/14)\n",
      "Test Accuracy of 58 -> geranium: 100.00% ( 7/ 7)\n",
      "Test Accuracy of 59 -> orange dahlia: 33.33% ( 3/ 9)\n",
      "Test Accuracy of 60 -> pink-yellow dahlia: 90.00% ( 9/10)\n",
      "Test Accuracy of 61 -> cautleya spicata: 100.00% ( 8/ 8)\n",
      "Test Accuracy of 62 -> japanese anemone: 25.00% ( 1/ 4)\n",
      "Test Accuracy of 63 -> black-eyed susan: 25.00% ( 1/ 4)\n",
      "Test Accuracy of 64 -> silverbush: 40.00% ( 2/ 5)\n",
      "Test Accuracy of 65 -> californian poppy: 85.71% ( 6/ 7)\n",
      "Test Accuracy of 66 -> osteospermum: 50.00% ( 2/ 4)\n",
      "Test Accuracy of 67 -> spring crocus: 0.00% ( 0/ 4)\n",
      "Test Accuracy of 68 -> bearded iris: 33.33% ( 1/ 3)\n",
      "Test Accuracy of 69 -> windflower: 100.00% ( 3/ 3)\n",
      "Test Accuracy of 70 -> tree poppy: 33.33% ( 2/ 6)\n",
      "Test Accuracy of 71 -> gazania: 75.00% ( 3/ 4)\n",
      "Test Accuracy of 72 -> azalea: 22.22% ( 2/ 9)\n",
      "Test Accuracy of 73 -> water lily: 9.09% ( 1/11)\n",
      "Test Accuracy of 74 ->  rose: 64.29% (18/28)\n",
      "Test Accuracy of 75 -> thorn apple: 28.57% ( 4/14)\n",
      "Test Accuracy of 76 -> morning glory: 84.62% (11/13)\n",
      "Test Accuracy of 77 -> passion flower: 25.00% ( 1/ 4)\n",
      "Test Accuracy of 78 -> lotus lotus: 92.00% (23/25)\n",
      "Test Accuracy of 79 -> toad lily: 78.57% (11/14)\n",
      "Test Accuracy of 80 -> anthurium: 33.33% ( 1/ 3)\n",
      "Test Accuracy of 81 -> frangipani: 70.00% ( 7/10)\n",
      "Test Accuracy of 82 -> clematis: 0.00% ( 0/11)\n",
      "Test Accuracy of 83 -> hibiscus: 61.54% ( 8/13)\n",
      "Test Accuracy of 84 -> columbine: 17.65% ( 3/17)\n",
      "Test Accuracy of 85 -> desert-rose: 42.86% ( 6/14)\n",
      "Test Accuracy of 86 -> tree mallow: 20.00% ( 2/10)\n",
      "Test Accuracy of 87 -> magnolia: 70.00% ( 7/10)\n",
      "Test Accuracy of 88 -> cyclamen: 60.00% ( 3/ 5)\n",
      "Test Accuracy of 89 -> watercress: 33.33% ( 2/ 6)\n",
      "Test Accuracy of 90 -> canna lily: 30.77% ( 4/13)\n",
      "Test Accuracy of 91 -> hippeastrum: 60.00% ( 9/15)\n",
      "Test Accuracy of 92 -> bee balm: 0.00% ( 0/ 2)\n",
      "Test Accuracy of 93 -> ball moss: 7.14% ( 1/14)\n",
      "Test Accuracy of 94 -> foxglove: 50.00% ( 4/ 8)\n",
      "Test Accuracy of 95 -> bougainvillea: 36.36% ( 4/11)\n",
      "Test Accuracy of 96 -> camellia: 16.67% ( 1/ 6)\n",
      "Test Accuracy of 97 -> mallow: 50.00% ( 8/16)\n",
      "Test Accuracy of 98 -> mexican petunia: 0.00% ( 0/14)\n",
      "Test Accuracy of 99 -> bromelia: 22.22% ( 2/ 9)\n",
      "Test Accuracy of 100 -> blanket flower: 20.00% ( 1/ 5)\n",
      "Test Accuracy of 101 -> trumpet creeper: 50.00% ( 2/ 4)\n",
      "Test Accuracy of 102 -> blackberry lily: 0.00% ( 0/ 7)\n",
      "\n",
      "Test Accuracy (Overall): 46.52% (381/819)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(class_total)):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %2d -> %5s: %.2f%% (%2d/%2d)' % (i+1,\n",
    "            cat_to_name[str(i+1)], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (class_total[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %.2f%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference for classification\n",
    "\n",
    "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```\n",
    "\n",
    "First you'll need to handle processing the input image such that it can be used in your network. \n",
    "\n",
    "## Image Preprocessing\n",
    "\n",
    "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
    "\n",
    "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
    "\n",
    "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
    "\n",
    "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
    "\n",
    "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    \n",
    "    # TODO: Process a PIL image for use in a PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Prediction\n",
    "\n",
    "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
    "\n",
    "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
    "\n",
    "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
    "\n",
    "```python\n",
    "probs, classes = predict(image_path, model)\n",
    "print(probs)\n",
    "print(classes)\n",
    "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
    "> ['70', '3', '45', '62', '55']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, model, topk=5):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Implement the code to predict the class from an image file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checking\n",
    "\n",
    "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the validation accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
    "\n",
    "<img src='assets/inference_example.png' width=300px>\n",
    "\n",
    "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display an image along with the top 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, losslogger, filename='checkpoint.pth.tar'):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        losslogger = checkpoint['losslogger']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch, losslogger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
